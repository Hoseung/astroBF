{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03edea64",
   "metadata": {},
   "source": [
    "Demo from https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805a964",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d067b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 29 16:45:19 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3060    Off  | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   46C    P8    18W / 170W |    812MiB / 12050MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1330      G   /usr/lib/xorg/Xorg                545MiB |\n",
      "|    0   N/A  N/A      1585      G   /usr/bin/gnome-shell               65MiB |\n",
      "|    0   N/A  N/A     52892      G   ...AAAAAAAAA= --shared-files       20MiB |\n",
      "|    0   N/A  N/A     53066      G   ...AAAAAAAAA= --shared-files      131MiB |\n",
      "|    0   N/A  N/A     54465      G   ...gAAAAAAAAA --shared-files       44MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi -i 0\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import resnet\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff9075a-47e4-4d9f-b88d-997ab87c1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "# Why would I want to use cmd arguments??\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.arch='resnet18' \n",
    "args.batch_size=512 \n",
    "args.bn_splits=8 \n",
    "args.cos=True \n",
    "args.epochs=200 \n",
    "args.knn_k=200 \n",
    "args.knn_t=0.1 \n",
    "args.lr=0.06 \n",
    "args.moco_dim=128 \n",
    "args.moco_k=4096 \n",
    "args.moco_m=0.99 \n",
    "args.moco_t=0.1 \n",
    "args.results_dir='./cache-2021-07-29-03-55-17-moco' \n",
    "args.resume='' \n",
    "args.schedule=[] \n",
    "args.symmetric=False \n",
    "args.wd=0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1056c5-e826-4844-921d-0f7311dc4e39",
   "metadata": {},
   "source": [
    "## Data loader \n",
    "\n",
    "Need train / memory / test data sets\n",
    "\n",
    "train set returns a pair of images (same image, differently transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff7d739-b4cc-4978-90e6-c19d605bbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "class TonemapImageDataset(VisionDataset):\n",
    "    def __init__(self, \n",
    "                 data_array, \n",
    "                 labels: Optional = None, \n",
    "                 train: bool=True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,):\n",
    "        self._array = data_array\n",
    "        self._good_gids = np.array([gal['img_name'] for gal in data_array])\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        For super\n",
    "        \"\"\"\n",
    "        image, _segmap, weight = self._array[idx]\n",
    "        image[_segmap] = np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "        \n",
    "        label = self.labels.iloc[idx]\n",
    "        return image\n",
    "    \n",
    "class TonemapImageDatasetPair(TonemapImageDataset):\n",
    "    \"\"\"\n",
    "    returns two differently (randomly) transformed version of an image.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        image, segmap, weight = self._array[idx]\n",
    "        \n",
    "        image[_segmap] = np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "        \n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(image) # random transform. \n",
    "            im_2 = self.transform(image)\n",
    "        return im_1, im_2\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb66e65a-88cd-42f4-82bb-5ad136a289c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "fn = \"../../bf_data/Nair_and_Abraham_2010/all_gals.pickle\"\n",
    "all_gals = pickle.load(open(fn, \"rb\"))\n",
    "\n",
    "all_gals = all_gals[1:] # Why the first galaxy image is NaN?\n",
    "\n",
    "good_gids = np.array([gal['img_name'] for gal in all_gals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6c942b-7c01-463d-8e2d-ef6dbf5a0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astrobf.utils.misc import load_Nair\n",
    "cat_data = load_Nair('../../bf_data/Nair_and_Abraham_2010/catalog/table2.dat')\n",
    "# pd dataframe\n",
    "\n",
    "cat = cat_data[cat_data['ID'].isin(good_gids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af33c29-09c6-4287-871c-312540c5d7f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TonemapImageDatasetPair' object has no attribute 'img_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3524dad04bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# data prepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTonemapImageDatasetPair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_gals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmemory_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTonemapImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_gals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     99\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# dataset size might change at runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f06b77c82931>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TonemapImageDatasetPair' object has no attribute 'img_labels'"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "# data prepare\n",
    "train_data = TonemapImageDatasetPair(all_gals, train=True, transform=train_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "memory_data = TonemapImageDataset(all_gals, train=True, transform=test_transform)\n",
    "memory_loader = DataLoader(memory_data, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "test_data = TonemapImageDataset(all_gals, train=False, transform=test_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5bd51-6445-4b55-8ae5-feb8d08728f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
